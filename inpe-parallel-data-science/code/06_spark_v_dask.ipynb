{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of Dask: Why to use Spark!\n",
    "\n",
    "Dask is well integrated into the python ecosystem. This is the best and worst part of dask.  \n",
    "* Best:\n",
    "  * dask inherites the efficient implementations of the underlying libraries in NumPy and pandas.\n",
    "  * dask is easy to use for python programers\n",
    "* Worst\n",
    "  * dask is python and python is a serial and interpreted (not compiled) language\n",
    "  * inefficient for user-defined functions (they run in python)\n",
    "  \n",
    "Ultimately, dask does not run on Hadoop! and, as a consequence, is not good at shuffling(sorting) data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dask bags\n",
    "\n",
    "### Dask Datatypes, Functions, and Operators\n",
    "\n",
    "Because Dask is a data parallel language, it's reasonable to categorize dask around the three major \"collections\" implemented:\n",
    "  * dask.array: a parallel NumPy array\n",
    "  * dask.dataframe: a parallel pandas dataframe\n",
    "  * dask.bag: inherited from Spark (and Pig).\n",
    "  \n",
    "So, arrays and dataframes make sense.  Where did this bag come from? Dask reports that \"It is similar to a parallel version of PyToolz or a Pythonic version of the PySpark RDD.\"\n",
    "\n",
    "A dask bag or multiset is:\n",
    "  * unordered: cannot be indexed like an array\n",
    "  * not-unique: can have repeated entries\n",
    "  * contains arbitrary python objects\n",
    "  \n",
    "The dask guidance is to only use bags when absolutely needed and to convert to arrays or dataframes as soon as possible. Bags support the nested data structures typical of JSON, e.g. dictionaries that contain lists of lists.  The limitations are:\n",
    "  * bags only use the 'processes' scheduler and cannot share memory among the multiple cores of a node\n",
    "  * user-defined functions are inefficient when compared with pandas or numpy builtints \n",
    "\n",
    "Additionally, dask **strongly** encourages you to avoid <code>bag.groupby()</code>, because it requires a full shuffle (sort by key) of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Guidance for dask:\n",
    "  * try to convert semi-structured data to dataframes as soon as possible\n",
    "  * try to use built-in functions whenever possible, they are compiled often\n",
    "  \n",
    "Guidance for when and how to use Spark:\n",
    "  * for workloads that perform shuffles, Spark runs on top of the Hadoop! engine.\n",
    "  * for complex user-defined functions, but you must write them in Scala which compiles into java.\n",
    "\n",
    "Spark is a bigger, heavier ecosystem with a more complex distributed query optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
