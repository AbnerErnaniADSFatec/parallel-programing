{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief history of data-parallel compute engines\n",
    "\n",
    "This short lecture introduces map/reduce which has led to an ecosystem of data-parallel processing engines.  Notable, dask is the only engine in this list that doesn't build on top of the map/reduce paradigm.\n",
    "\n",
    "### Map/Reduce (2004): \n",
    "\n",
    "At Google, Jeff Dean and Sanjay Ghemawat outline the future of large-scale data processing\n",
    "  * <code>map()</code>: applies a user-defined function to a data partition and outputs a <code>key</code> used to identify objects in a class and a <code>value</code> that contains the data.\n",
    "  * <code>reduce()</code>: takes all items with the same key and applies a user-defined function that aggregates the data.\n",
    "  * This was the start of automatic parallelism (some disagree). The programmer writes two _pure_ functions and creates a computation that scales to thousands of nodes and GB of data.\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*KKm4roOpsum147kKk5qp7A.jpeg\" width=512 />\n",
    "\n",
    "This introduce the concept of key/value processing.  Here's some pseduocode and a visualization of how it works.\n",
    "\n",
    "### Map/Reduce Example\n",
    "\n",
    "Wordcount example from the original Google paper. Produce a count of the occurrence of each word in a set of documents.\n",
    "\n",
    "```python\n",
    "    map ( String key, String value ):\n",
    "        // key: document name (file name)\n",
    "        // value: document contents\n",
    "        for each word w in value:\n",
    "            EmitIntermediate ( word, \"1\" );\n",
    "```\n",
    "\n",
    "Mapper outputs `key=word, value=\"1\"` for each word. Note that the output key and input key are different.\n",
    "\n",
    "```python\n",
    "    reduce ( String key, Iterator values ):\n",
    "        // key: a word\n",
    "        // value: a list of counts\n",
    "        int result = 0;\n",
    "        for each word v in values:\n",
    "            result += ParsseInt ( v );\n",
    "        EmitAsString ( result );\n",
    "```\n",
    "Reducer sums the counts of words.  Some properties:\n",
    "  * reducer gets a list of values at a key\n",
    "  * reduce cannot change the key, emits a value, that is reduced from list\n",
    "  * user defined function\n",
    "  \n",
    "### WordCount Visualized\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Oscar_Pereira3/publication/270448794/figure/fig6/AS:295098651824130@1447368409317/Word-count-program-flow-executed-with-MapReduce-5.png\" width=768 title=\"from Oscar Perreira @ ResearchGate\" />\n",
    "\n",
    "Map/reduce is a data-parallel, __streaming__ processing engine.  \n",
    " * input files are read sequentially from disk. \n",
    " * output files are written sequentially to disk. \n",
    "Good for many analysis tasks, but not good for iterative computations that reuse the output of one computation as input to the next.\n",
    "\n",
    "Still the preferred programming engine for:\n",
    "      * Web-log processing\n",
    "      * Reverse web-link graph\n",
    "      * Term vectors per host\n",
    "      * Inverted index\n",
    "      * Distributed sort\n",
    "      \n",
    "Distributed sort is what happens with a NULL mapper and a single NULL reducer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadoop! (2006):\n",
    "\n",
    "Open source implementation of map/reduce computing\n",
    "  * Credit to Doug Cutting and Mike Cafarella.\n",
    "  * Users write Java functions that execute at scale.\n",
    "  \n",
    "We now move out of the Google ecosystem. Google has continued to make important contributions that inform open-source.\n",
    "\n",
    "### Pig (2008): Meta-programming for Hadoop!\n",
    "\n",
    "  * declarative constructs that compile to map/reduce programs\n",
    "  * adopts the bag data type as an abstraction for key/value data \n",
    "  \n",
    "```pig\n",
    "lines = LOAD '/user/hadoop/HDFS_File.txt' AS (line:chararray);\n",
    "words = FOREACH lines GENERATE FLATTEN(TOKENIZE(line)) as word;\n",
    "grouped = GROUP words BY word;\n",
    "wordcount = FOREACH grouped GENERATE group, COUNT(words);\n",
    "DUMP wordcount;\n",
    "```\n",
    "  \n",
    "### Hive (2010): An SQL(-like) interface to Hadoop!\n",
    "\n",
    "  * Most SQL queries can be executed in two iterations of map/reduce\n",
    "  * Similar to dask/pandas, Hive only implemented the part of SQL that translates to M/R\n",
    "\n",
    "```sql\n",
    "CREATE TABLE word_counts AS\n",
    "SELECT word, count(1) AS count FROM\n",
    "(SELECT explode(split(line, ' ')) AS word FROM FILES) w\n",
    "GROUP BY word\n",
    "ORDER BY word;\n",
    "```\n",
    "\n",
    "### Spark (2014): \n",
    "In-memory data for iterative programming in map/reduce\n",
    "\n",
    "### Dask (2016?): \n",
    "\"pythonic\" version of Spark that eases programming for NumPy and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
