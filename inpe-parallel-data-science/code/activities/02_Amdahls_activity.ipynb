{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reductions and Strong Scaling\n",
    "\n",
    "Reduction is the process of applying an operator to all elements in a vector/matrix typically to output a scalar.  Wikipedia says, 'Reduce is a collective communication primitive used in the context of a parallel programming model to combine multiple vectors into one, using an associative binary operator $\\oplus$.  It is easiest to envision this operation on a tree with addition\n",
    "\n",
    "![this](https://upload.wikimedia.org/wikipedia/commons/e/ee/Binomial_tree.gif)\n",
    "\n",
    "The most common way to execute a reduction is a tree-hierarchy of blocks (chunks) of elements.\n",
    "  1. reduce each chunk to a scalar\n",
    "  2. build new chunks of scalars ouput from step 1. \n",
    "  3. repeat\n",
    "There are more complex approaches that involve pipelining results that might be faster on some architectures. Not important.\n",
    "\n",
    "Dask and other frameworks do this implicitly when calling aggregation functions, <code>mean, min, max, sum</code> and explicitly with a user defined function <code>dask.bag.fold()</code> and <code>dask.bag.foldby()</code>.\n",
    "\n",
    "Let's compute an aggregate on our turbulent field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import h5py\n",
    "\n",
    "# load a file and grab the data\n",
    "f = h5py.File(\"../../input/isotropic4096.h5\",\"r\")\n",
    "d = f['u00000']\n",
    "\n",
    "# convert data into a dask array and take the velocity magnitude\n",
    "uvec = da.from_array(d[0,:,:,:], chunks=(512, 512, 3))\n",
    "umag = da.linalg.norm(uvec, axis=2)\n",
    "\n",
    "# hint dask to keep this around\n",
    "umag.persist()\n",
    "\n",
    "# compute the maximum velocity \n",
    "umag.max().compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design an experiment to measure the speedup of this computation for 1, 2, 4, 8 workers.  From that speedup, infer the Amdahl number of this reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# compute once to get any caches warm\n",
    "umag.max().compute()\n",
    "\n",
    "# list to store timings\n",
    "exptimes=[]\n",
    "\n",
    "for cores in [1,2,4,8]:\n",
    "    for trials in range(20):\n",
    "        start = time.perf_counter()\n",
    "        # ... tell dask how many cores to use\n",
    "        tdiff = time.perf_counter() - start\n",
    "        exptimes.append([cores,tdiff])    \n",
    "\n",
    "df = pd.DataFrame(exptimes, columns = [\"cores\",\"time\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the raw data\n",
    "\n",
    "Describe the data frame to show summary statistics and then plot the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('cores').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df.plot(x='cores', y='time', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speedup Chart\n",
    "\n",
    "Use your data to make a speeedup chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Efficiency Chart\n",
    "\n",
    "Same with a parallel efficiency chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "\n",
    "# this line of code is helpful in converting the index data back into data\n",
    "df.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the Amdahl Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "\n",
    "* Why did scaling stop after 4 cores?\n",
    "  * My laptop has 4 cores and 8 threads, what does this mean?\n",
    "* Why is the Amdahl number so low?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
